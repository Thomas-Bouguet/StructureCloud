{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.1.170.112:4040\n",
       "SparkContext available as 'sc' (version = 3.4.1, master = local[*], app id = local-1702999175995)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{SparkSession, functions=>F}\r\n",
       "old_data_path: String = C:/Thomas/Etudes/ESILV/A9/Structure_de_donnees_cloud/Projet/Report_4/startingTables/\r\n",
       "new_data_path: String = C:/Thomas/Etudes/ESILV/A9/Structure_de_donnees_cloud/Projet/Report_4/denTables/\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SparkSession, functions => F}\n",
    "\n",
    "var old_data_path = \"C:/Thomas/Etudes/ESILV/A9/Structure_de_donnees_cloud/Projet/Report_4/startingTables/\"\n",
    "var new_data_path = \"C:/Thomas/Etudes/ESILV/A9/Structure_de_donnees_cloud/Projet/Report_4/denTables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@53531bf9\r\n",
       "moviesDF: org.apache.spark.sql.DataFrame = [id: string, name: string ... 2 more fields]\r\n",
       "oldMoviesGenresDF: org.apache.spark.sql.DataFrame = [movie_id: string, genre: string]\r\n",
       "oldMoviesDirectorsDF: org.apache.spark.sql.DataFrame = [director_id: string, movie_id: string]\r\n",
       "oldRolesDF: org.apache.spark.sql.DataFrame = [actor_id: string, movie_id: string ... 1 more field]\r\n",
       "directorsDF: org.apache.spark.sql.DataFrame = [id: string, first_name: string ... 1 more field]\r\n",
       "oldDirectorsGenresDF: org.apache.spark.sql.DataFrame = [director_id: string, genre: string ... 1 more field]\r\n",
       "actorsDF: org.apache.spark.sql.DataFrame = [id: string, first_name: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a Spark session\n",
    "val spark = SparkSession.builder.appName(\"Denormalization\")\n",
    "  .config(\"spark.driver.memory\", \"8g\")\n",
    "  .config(\"spark.executor.memory\", \"8g\")\n",
    "  .getOrCreate()\n",
    "\n",
    "// Load the CSV data into DataFrames\n",
    "val moviesDF = spark.read.csv(old_data_path + \"movies.csv\").toDF(\"id\",\"name\",\"year\",\"rank\")\n",
    "val oldMoviesGenresDF = spark.read.csv(old_data_path + \"movies_genres.csv\").toDF(\"movie_id\",\"genre\")\n",
    "val oldMoviesDirectorsDF = spark.read.csv(old_data_path + \"movies_directors.csv\").toDF(\"director_id\",\"movie_id\")\n",
    "val oldRolesDF = spark.read.csv(old_data_path + \"roles.csv\").toDF(\"actor_id\",\"movie_id\",\"role\")\n",
    "\n",
    "val directorsDF = spark.read.csv(old_data_path + \"directors.csv\").toDF(\"id\", \"first_name\", \"last_name\")\n",
    "val oldDirectorsGenresDF = spark.read.csv(old_data_path + \"directors_genres.csv\").toDF(\"director_id\",\"genre\",\"prob\")\n",
    "\n",
    "val actorsDF = spark.read.csv(old_data_path + \"actors.csv\").toDF(\"id\",\"first_name\",\"last_name\",\"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedMoviesDF: org.apache.spark.sql.DataFrame = [id: string, name: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize movies.list_genres\n",
    "val denormalizedMoviesDF = moviesDF\n",
    "  .join(oldMoviesGenresDF, moviesDF(\"id\") === oldMoviesGenresDF(\"movie_id\"), \"left_outer\")\n",
    "  .groupBy(\"id\", \"name\", \"year\", \"rank\")\n",
    "  .agg(F.collect_list(\"genre\").alias(\"list_genres\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedMoviesWithDirectorsDF: org.apache.spark.sql.DataFrame = [id: string, name: string ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize movies.list_directors_id\n",
    "val denormalizedMoviesWithDirectorsDF = denormalizedMoviesDF\n",
    "  .join(oldMoviesDirectorsDF, denormalizedMoviesDF(\"id\") === oldMoviesDirectorsDF(\"movie_id\"), \"left_outer\")\n",
    "  .groupBy(\"id\", \"name\", \"year\", \"rank\", \"list_genres\")\n",
    "  .agg(F.collect_list(\"director_id\").alias(\"list_directors_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedMoviesWithActorsDF: org.apache.spark.sql.DataFrame = [id: int, name: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize movies.den_nb_actors\n",
    "val denormalizedMoviesWithActorsDF = denormalizedMoviesWithDirectorsDF\n",
    "  .join(oldRolesDF, denormalizedMoviesWithDirectorsDF(\"id\") === oldRolesDF(\"movie_id\"), \"left_outer\")\n",
    "  .groupBy(\"id\", \"name\", \"year\", \"rank\", \"list_genres\", \"list_directors_id\")\n",
    "  .agg(F.size(F.collect_list(\"actor_id\")).alias(\"den_nb_actors\"))\n",
    "  .withColumn(\"id\", $\"id\".cast(\"int\"))\n",
    "  .withColumn(\"list_directors_id\", $\"list_directors_id\".cast(\"array<int>\"))\n",
    "  .withColumn(\"year\", $\"year\".cast(\"int\"))\n",
    "  .withColumn(\"rank\", $\"rank\".cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedDirectorsWithMoviesDF: org.apache.spark.sql.DataFrame = [id: string, first_name: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize directors.list_movies_id\n",
    "val denormalizedDirectorsWithMoviesDF = directorsDF\n",
    "  .join(oldMoviesDirectorsDF, directorsDF(\"id\") === oldMoviesDirectorsDF(\"director_id\"),\"left_outer\")\n",
    "  .groupBy(\"id\",\"first_name\",\"last_name\")\n",
    "  .agg(F.collect_list(\"movie_id\").alias(\"list_movies_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedDirectorsDF: org.apache.spark.sql.DataFrame = [id: int, first_name: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize directors.dict_genres_den_prob\n",
    "val denormalizedDirectorsDF = denormalizedDirectorsWithMoviesDF\n",
    "  .join(oldDirectorsGenresDF, denormalizedDirectorsWithMoviesDF(\"id\") === oldDirectorsGenresDF(\"director_id\"), \"left_outer\")\n",
    "  .groupBy(\"id\", \"first_name\", \"last_name\", \"list_movies_id\")\n",
    "  .agg(\n",
    "    F.map_from_entries(\n",
    "      F.collect_list(\n",
    "        F.when(\n",
    "          F.col(\"genre\").isNotNull && F.col(\"prob\").isNotNull,\n",
    "          F.struct(\"genre\", \"prob\")\n",
    "        )\n",
    "      )\n",
    "    ).alias(\"dict_genres_den_prob\")\n",
    "  )\n",
    "  .withColumn(\"id\", $\"id\".cast(\"int\"))\n",
    "  .withColumn(\"list_movies_id\", $\"list_movies_id\".cast(\"array<int>\"))\n",
    "  // .withColumn(\"dict_genres_den_prob\", $\"dict_genres_den_prob\".cast(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convertToFloat: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4070/0x0000000801c5eca8@3a109b5c,MapType(StringType,FloatType,false),List(Some(class[value[0]: map<string,string>])),Some(class[value[0]: map<string,float>]),None,true,true)\r\n",
       "denormalizedDirectorsDFWithGoodTypes: org.apache.spark.sql.DataFrame = [id: int, first_name: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Function to convert string values of dictionary into float\n",
    "val convertToFloat = udf((data: Map[String, String]) =>\n",
    "  data.mapValues(_.toFloat)\n",
    ")\n",
    "\n",
    "// Apply the function to column \"dict_genres_den_prob\"\n",
    "val denormalizedDirectorsDFWithGoodTypes = denormalizedDirectorsDF.withColumn(\n",
    "  \"dict_genres_den_prob\",\n",
    "  convertToFloat(col(\"dict_genres_den_prob\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denormalizedActorsDF: org.apache.spark.sql.DataFrame = [id: int, first_name: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Denormalize actors.list_movies_id\n",
    "val denormalizedActorsDF = actorsDF\n",
    "  .join(oldRolesDF, actorsDF(\"id\") === oldRolesDF(\"actor_id\"), \"left_outer\")\n",
    "  .groupBy(\"id\", \"first_name\", \"last_name\")\n",
    "  .agg(F.collect_list(\"movie_id\").alias(\"list_movies_id\"))\n",
    "  .withColumn(\"id\", $\"id\".cast(\"int\"))\n",
    "  .withColumn(\"list_movies_id\", $\"list_movies_id\".cast(\"array<int>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the denormalized data to a JSON file\n",
    "denormalizedActorsDF.coalesce(1).write.mode(\"overwrite\").format(\"json\").save(new_data_path + \"denActors.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the denormalized data to a JSON file\n",
    "denormalizedDirectorsDFWithGoodTypes.coalesce(1).write\n",
    "  .mode(\"overwrite\") // Use \"overwrite\" or \"append\" based on your requirement\n",
    "  .format(\"json\")\n",
    "  .save(new_data_path + \"denDirectors.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save the denormalized data to a JSON file\n",
    "denormalizedMoviesWithActorsDF.coalesce(1).write\n",
    "  .mode(\"overwrite\") // Use \"overwrite\" or \"append\" based on your requirement\n",
    "  .format(\"json\")\n",
    "  .save(new_data_path + \"denMovies.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
